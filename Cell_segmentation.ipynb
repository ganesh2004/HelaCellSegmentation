{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "TO-Kp9KeaLEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import albumentations as A\n"
      ],
      "metadata": {
        "id": "49hWzqMnZUDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Config"
      ],
      "metadata": {
        "id": "moXTlpGfaiBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image dimensions and channels\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "# Directories for input images and ground-truth masks\n",
        "INPUT_DIR = 'drive/MyDrive/DIP/BW'\n",
        "GT_DIR = 'drive/MyDrive/DIP/ground_truth'\n",
        "\n",
        "# Class values in the mask (hard-coded)\n",
        "CELL_PIXEL_VALUES = [51, 102, 255]\n",
        "\n",
        "# Training hyperparameters\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 100\n",
        "PATIENCE = 15\n",
        "\n",
        "@Helpers\n",
        "def load_grayscale_image(path):\n",
        "    \"\"\"\n",
        "    Load an image in grayscale mode.\n",
        "    Returns the image array or None if loading fails.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Warning: Could not read {path}\")\n",
        "    return img\n",
        "\n",
        "@Paths\n",
        "def get_image_paths(input_dir, gt_dir):\n",
        "    \"\"\"\n",
        "    Collect and pair PNG filenames from input and ground-truth directories.\n",
        "    Filenames must match exactly; else raises an error.\n",
        "    \"\"\"\n",
        "    inputs = sorted(f for f in os.listdir(input_dir) if f.endswith('.png'))\n",
        "    gts = sorted(f for f in os.listdir(gt_dir) if f.endswith('.png'))\n",
        "    if len(inputs) != len(gts):\n",
        "        raise ValueError(\"Mismatched counts of input and ground truth images.\")\n",
        "    # Return full file paths for both lists\n",
        "    return ([os.path.join(input_dir, f) for f in inputs],\n",
        "            [os.path.join(gt_dir, f) for f in gts])"
      ],
      "metadata": {
        "id": "7nPruzUFa_ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataGen"
      ],
      "metadata": {
        "id": "1ZharKIhbD6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"\n",
        "    Keras Sequence for batch-wise loading and augmentation of images and masks.\n",
        "    Applies augmentations if provided, normalizes images, and binarizes masks.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_paths, mask_paths, cell_values,\n",
        "                 batch_size=BATCH_SIZE, dim=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                 n_channels=IMG_CHANNELS, shuffle=True, augmentations=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.cell_values = cell_values\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.augmentations = augmentations\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of batches per epoch\n",
        "        return len(self.image_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Generate one batch of data\n",
        "        idxs = self.indexes[idx*self.batch_size : (idx+1)*self.batch_size]\n",
        "        batch_imgs = [self.image_paths[i] for i in idxs]\n",
        "        batch_masks = [self.mask_paths[i] for i in idxs]\n",
        "        return self._generate(batch_imgs, batch_masks)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _generate(self, imgs, masks):\n",
        "        # Initialize arrays for images and masks\n",
        "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n",
        "        y = np.zeros((self.batch_size, *self.dim, 1), dtype=np.float32)\n",
        "        for i, (img_p, mask_p) in enumerate(zip(imgs, masks)):\n",
        "            img = load_grayscale_image(img_p)\n",
        "            m = load_grayscale_image(mask_p)\n",
        "            # Apply augmentations if provided, else just resize\n",
        "            if self.augmentations:\n",
        "                aug = self.augmentations(image=img, mask=m)\n",
        "                img, m = aug['image'], aug['mask']\n",
        "            else:\n",
        "                img = cv2.resize(img, self.dim)\n",
        "                m = cv2.resize(m, self.dim, interpolation=cv2.INTER_NEAREST)\n",
        "            # Normalize image and binarize mask based on class values\n",
        "            X[i,...,0] = img / 255.0\n",
        "            y[i,...,0] = np.isin(m, self.cell_values).astype(np.float32)\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "-nYc78BIbIaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Augmentations"
      ],
      "metadata": {
        "id": "gg3Yk8eRbJPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation for training and basic resize for validation\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(IMG_HEIGHT, IMG_WIDTH, interpolation=cv2.INTER_NEAREST),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=35, p=0.3, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.ElasticTransform(p=0.3, alpha=120, sigma=6, alpha_affine=3),\n",
        "    A.RandomBrightnessContrast(p=0.3)\n",
        "])\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(IMG_HEIGHT, IMG_WIDTH, interpolation=cv2.INTER_NEAREST)\n",
        "])"
      ],
      "metadata": {
        "id": "azUyUS1TbOsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "RSCjfc7JbQNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape):\n",
        "    \"\"\"\n",
        "    Constructs a U-Net model for binary segmentation.\n",
        "\n",
        "    Encoder: repeated conv + pool\n",
        "    Decoder: transpose conv, skip-concat, and conv\n",
        "    Final layer: 1x1 conv with sigmoid activation\n",
        "    \"\"\"\n",
        "    def conv_block(x, filters):\n",
        "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        return layers.ReLU()(x)\n",
        "\n",
        "    def encoder(x, f):\n",
        "        c = conv_block(x, f)\n",
        "        p = layers.MaxPool2D()(c)\n",
        "        return c, p\n",
        "\n",
        "    def decoder(x, skip, f):\n",
        "        x = layers.Conv2DTranspose(f, 2, strides=2, padding='same')(x)\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "        return conv_block(x, f)\n",
        "\n",
        "    inputs = keras.Input((*input_shape,))\n",
        "    s1, p1 = encoder(inputs, 64)\n",
        "    s2, p2 = encoder(p1, 128)\n",
        "    s3, p3 = encoder(p2, 256)\n",
        "    s4, p4 = encoder(p3, 512)\n",
        "    b = conv_block(p4, 1024)\n",
        "    d1 = decoder(b, s4, 512)\n",
        "    d2 = decoder(d1, s3, 256)\n",
        "    d3 = decoder(d2, s2, 128)\n",
        "    d4 = decoder(d3, s1, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(d4)\n",
        "    return keras.Model(inputs, outputs, name='U-Net')"
      ],
      "metadata": {
        "id": "X6cYZyW5bVFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "DS0EWQg-bXBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zWmzrzNZRca"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load and split data, create generators\n",
        "    img_paths, mask_paths = get_image_paths(INPUT_DIR, GT_DIR)\n",
        "    train_gen, val_gen, test_x, test_y = None, None, [], []\n",
        "    # Use helper function to split and create generators\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    train_gen, val_gen, test_x, test_y = (\n",
        "        DataGenerator(*train_test_split(img_paths, mask_paths, test_size=0.3, random_state=42, stratify=None),\n",
        "                      cell_values=CELL_PIXEL_VALUES,\n",
        "                      augmentations=train_transform),\n",
        "        DataGenerator(*train_test_split(img_paths, mask_paths, test_size=0.3, random_state=42, stratify=None),\n",
        "                      cell_values=CELL_PIXEL_VALUES,\n",
        "                      shuffle=False, augmentations=val_transform),\n",
        "        [], []  # test lists built later\n",
        "    )\n",
        "    # Build and compile model\n",
        "    model = build_unet((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    # Callbacks: save best, adjust LR, early stop\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint('best.h5', save_best_only=True),\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=PATIENCE//2),\n",
        "        keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True)\n",
        "    ]\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    # Evaluate on test set if available\n",
        "    if test_x:\n",
        "        X_test, y_test = [], []\n",
        "        for xi, mi in zip(test_x, test_y):\n",
        "            img = load_grayscale_image(xi)\n",
        "            m = load_grayscale_image(mi)\n",
        "            t = val_transform(image=img, mask=m)\n",
        "            X_test.append(t['image'][...,None] / 255)\n",
        "            y_test.append(np.isin(t['mask'], CELL_PIXEL_VALUES)[...,None])\n",
        "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "        print(model.evaluate(X_test, y_test))\n",
        "    # Plot training loss curves\n",
        "    plt.plot(history.history['loss'], label='loss')\n",
        "    plt.plot(history.history.get('val_loss', []), label='val_loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    }
  ]
}