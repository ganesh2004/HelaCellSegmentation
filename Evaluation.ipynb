{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "9vyfWh66br-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2  # OpenCV for image IO\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import pandas as pd\n",
        "import albumentations as A"
      ],
      "metadata": {
        "id": "Uw86kK4_buhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Config"
      ],
      "metadata": {
        "id": "EtmKDMCdbwe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic configuration: image size, directories, and mask class values\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 1\n",
        "INPUT_DIR = 'drive/MyDrive/DIP/BW'\n",
        "GT_DIR = 'drive/MyDrive/DIP/ground_truth'\n",
        "PREDICTIONS_DIR = 'drive/MyDrive/DIP/predicted_masks_final'\n",
        "CELL_PIXEL_VALUES = [51, 102, 255]  # Pre-determined mask intensity values"
      ],
      "metadata": {
        "id": "W6-TSw_AbzIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transforms"
      ],
      "metadata": {
        "id": "ZU4VsABIb4TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation transform: resize mask and image to target dimensions\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(height=IMG_HEIGHT, width=IMG_WIDTH,\n",
        "             interpolation=cv2.INTER_NEAREST, always_apply=True)\n",
        "])"
      ],
      "metadata": {
        "id": "shmSv10Lb70p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ModelLoad"
      ],
      "metadata": {
        "id": "zabfzuL6cBmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the U-Net model is available and loaded with best weights\n",
        "model_load_path = 'unet_hela_best.keras'\n",
        "if 'model' not in locals() or model is None:\n",
        "    if os.path.exists(model_load_path):\n",
        "        print(f\"Loading model weights from: {model_load_path}\")\n",
        "        # Rebuild U-Net architecture if needed\n",
        "        from tensorflow.keras import layers\n",
        "        def conv_block(i, n):\n",
        "            x = layers.Conv2D(n, 3, padding='same')(i)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Activation('relu')(x)\n",
        "            x = layers.Conv2D(n, 3, padding='same')(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            return layers.Activation('relu')(x)\n",
        "        def encoder_block(i, n):\n",
        "            c = conv_block(i, n)\n",
        "            p = layers.MaxPooling2D((2,2))(c)\n",
        "            return c, p\n",
        "        def decoder_block(i, s, n):\n",
        "            x = layers.Conv2DTranspose(n, 2, strides=(2,2), padding='same')(i)\n",
        "            x = layers.Concatenate(axis=-1)([x, s])\n",
        "            return conv_block(x, n)\n",
        "        def build_unet(input_shape):\n",
        "            inputs = keras.Input(shape=input_shape)\n",
        "            s1, p1 = encoder_block(inputs, 64)\n",
        "            s2, p2 = encoder_block(p1, 128)\n",
        "            s3, p3 = encoder_block(p2, 256)\n",
        "            s4, p4 = encoder_block(p3, 512)\n",
        "            b1 = conv_block(p4, 1024)\n",
        "            d1 = decoder_block(b1, s4, 512)\n",
        "            d2 = decoder_block(d1, s3, 256)\n",
        "            d3 = decoder_block(d2, s2, 128)\n",
        "            d4 = decoder_block(d3, s1, 64)\n",
        "            outputs = layers.Conv2D(1, 1, activation='sigmoid')(d4)\n",
        "            return keras.Model(inputs, outputs, name='U-Net')\n",
        "        model = build_unet((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "        model.load_weights(model_load_path)\n",
        "        print(\"Model rebuilt and weights loaded.\")\n",
        "    else:\n",
        "        print(f\"Error: Model file {model_load_path} not found.\")\n",
        "        sys.exit()\n",
        "else:\n",
        "    print(\"Using pre-loaded model variable.\")"
      ],
      "metadata": {
        "id": "_xE47MRncKX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helpers"
      ],
      "metadata": {
        "id": "FMb00l1gcLvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image in grayscale mode, return None on failure\n",
        "def load_grayscale_image(path):\n",
        "    try:\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read {path}\")\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "J_-AbZ4McOTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paths"
      ],
      "metadata": {
        "id": "rjDXrrbUcQTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair input and GT images by filename, ensuring exact match\n",
        "def get_image_paths(input_dir, gt_dir):\n",
        "    inputs = sorted(f for f in os.listdir(input_dir) if f.endswith('.png'))\n",
        "    gts = sorted(f for f in os.listdir(gt_dir) if f.endswith('.png'))\n",
        "    if len(inputs) != len(gts):\n",
        "        raise ValueError(\"Input/GT PNG count mismatch.\")\n",
        "    paired = [(os.path.join(input_dir, f), os.path.join(gt_dir, f))\n",
        "              for f in inputs]\n",
        "    return zip(*paired)"
      ],
      "metadata": {
        "id": "h7biYkSjcSG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics"
      ],
      "metadata": {
        "id": "IcsgE4YpcT1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to compute TP, TN, FP, FN and derive IoU, Dice, F1, accuracy\n",
        "\n",
        "def numpy_calculate_stats(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    TP = np.sum((y_true_f == 1) & (y_pred_f == 1))\n",
        "    TN = np.sum((y_true_f == 0) & (y_pred_f == 0))\n",
        "    FP = np.sum((y_true_f == 0) & (y_pred_f == 1))\n",
        "    FN = np.sum((y_true_f == 1) & (y_pred_f == 0))\n",
        "    return TP, TN, FP, FN\n",
        "\n",
        "def numpy_jaccard(TP, TN, FP, FN, smooth=1e-6):\n",
        "    return (TP + smooth) / (TP + FP + FN + smooth)\n",
        "\n",
        "def numpy_dice(TP, TN, FP, FN, smooth=1e-6):\n",
        "    return (2 * TP + smooth) / (2 * TP + FP + FN + smooth)\n",
        "\n",
        "def numpy_f1_score(TP, TN, FP, FN, smooth=1e-6):\n",
        "    precision = (TP + smooth) / (TP + FP + smooth)\n",
        "    recall = (TP + smooth) / (TP + FN + smooth)\n",
        "    return (2 * precision * recall + smooth) / (precision + recall + smooth)\n",
        "\n",
        "def numpy_accuracy(TP, TN, FP, FN):\n",
        "    total = TP + TN + FP + FN\n",
        "    return (TP + TN) / total if total else 0.0"
      ],
      "metadata": {
        "id": "8e2TyK0ScV5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "30X9rwGscW4J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN33nWEwbn0G"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Prepare output folder and gather image pairs\n",
        "    os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
        "    inputs, gts = get_image_paths(INPUT_DIR, GT_DIR)\n",
        "\n",
        "    # Containers for per-image metrics\n",
        "    iou_scores, dice_scores, f1_scores, acc_scores = [], [], [], []\n",
        "\n",
        "    # Iterate over images: preprocess, predict, save, and evaluate\n",
        "    for idx, (inp, gt) in enumerate(zip(inputs, gts), 1):\n",
        "        img = load_grayscale_image(inp)\n",
        "        mask_gt = load_grayscale_image(gt)\n",
        "        if img is None or mask_gt is None:\n",
        "            print(f\"Skipping {inp}\")\n",
        "            continue\n",
        "        # Preprocess input\n",
        "        tr = val_transform(image=img)\n",
        "        inp_norm = tr['image'].astype(np.float32) / 255.0\n",
        "        inp_tensor = inp_norm[None, ..., None]\n",
        "        # Model prediction\n",
        "        pred_prob = model.predict(inp_tensor, verbose=0)[0]\n",
        "        pred_bin = (pred_prob > 0.5).astype(np.float32)\n",
        "        # Save binary mask\n",
        "        save_path = os.path.join(PREDICTIONS_DIR, os.path.basename(inp))\n",
        "        cv2.imwrite(save_path, (pred_bin.squeeze() * 255).astype(np.uint8))\n",
        "        # Prepare GT for metrics\n",
        "        gt_tr = val_transform(image=mask_gt)\n",
        "        gt_bin = np.isin(gt_tr['image'], CELL_PIXEL_VALUES).astype(np.float32)\n",
        "        # Compute stats and metrics\n",
        "        TP, TN, FP, FN = numpy_calculate_stats(gt_bin, pred_bin)\n",
        "        iou_scores.append(numpy_jaccard(TP, TN, FP, FN))\n",
        "        dice_scores.append(numpy_dice(TP, TN, FP, FN))\n",
        "        f1_scores.append(numpy_f1_score(TP, TN, FP, FN))\n",
        "        acc_scores.append(numpy_accuracy(TP, TN, FP, FN))\n",
        "\n",
        "    # Plot all metrics over image index\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(iou_scores, label='IoU')\n",
        "    plt.plot(dice_scores, label='Dice')\n",
        "    plt.plot(f1_scores, label='F1')\n",
        "    plt.plot(acc_scores, label='Accuracy')\n",
        "    plt.legend(); plt.title('Metrics per Image'); plt.xlabel('Image Index'); plt.ylabel('Score')\n",
        "    plt.show()\n",
        "\n",
        "    # Summarize metrics in a DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'IoU': iou_scores,\n",
        "        'Dice': dice_scores,\n",
        "        'F1': f1_scores,\n",
        "        'Accuracy': acc_scores\n",
        "    })\n",
        "    summary = df.agg(['mean', 'median', 'std']).round(4)\n",
        "    print(summary)\n"
      ]
    }
  ]
}